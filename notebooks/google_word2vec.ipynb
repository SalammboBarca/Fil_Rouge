{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook utilise un modèle glove google préentrainé téléchargé ici: http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/. \n",
    "Notebook inspiré de https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "# keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, GlobalMaxPool1D, Bidirectional, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.cfg')\n",
    "EMBEDDING_FILE=config['FILES']['GOOGLE']\n",
    "TRAIN_DATA_FILE=config['FILES']['TRAIN']\n",
    "TEST_DATA_FILE=config['FILES']['TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données sous forme de dataframes pandas\n",
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "# Définition des différents labels disponibles sous forme de liste\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # taille du vecteur\n",
    "max_features = 20000 # nombre de mots uniques utilisés (i.e nombre de lignes dans le vecteur d'embedding)\n",
    "maxlen = 100 # nombre maximum de mots à considérer dans un commentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On garde les mots les plus fréquents dans le jeu d'entrainement pour établir notre liste de tokens.\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "# Calcul des mots les plus fréquents\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "# Indexation des jeux d'entrainement et test, conversion du texte en séquence d'indexes\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation de Tokenizer: https://keras.io/preprocessing/text/\n",
    "et la documentation sur ses fonctions ici : http://faroit.com/keras-docs/1.2.2/preprocessing/text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les commentaires ont une longueur variable qui peut être inférieure à maxlen\n",
    "# On complète donc la séquence avec des 0, par défaut au début de la séquence\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation de pad_sequence ici: https://keras.io/preprocessing/sequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des vecteurs du modèle word2vec\n",
    "# Le fichier est encodé en binaire (.bin) -> binary=True\n",
    "word_vectors = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# le modèle pré-entrainé contient 3 millions de mots contre 20000 pour notre jeu de données.\n",
    "vocabulary_size=min(len(word_index)+1,max_features)\n",
    "\n",
    "# la matrice d'embedding représente le vocabulaire final à utiliser. \n",
    "# On ne gardera que 20000 vecteurs du modèle pré-entrainé. Leur longueur est de 300.\n",
    "embedding_matrix = np.zeros((vocabulary_size, embed_size))\n",
    "\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i>=max_features:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector    \n",
    "    except KeyError:\n",
    "        vec = np.zeros(embed_size)\n",
    "        embedding_matrix[i]=vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation d'input, dense et dropout: https://keras.io/layers/core/\n",
    "\n",
    "Documentation d'embedding: https://keras.io/layers/embeddings/\n",
    "\n",
    "Documentation des BRNNs: https://keras.io/layers/wrappers/\n",
    "\n",
    "Documentation des RNN: https://keras.io/layers/recurrent/\n",
    "\n",
    "Documentation du pooling: https://keras.io/layers/pooling/\n",
    "\n",
    "Documentation de l'activation: https://keras.io/activations/\n",
    "\n",
    "Documentation de l'optimiseur: https://keras.io/optimizers/\n",
    "\n",
    "Documentation de la fonction de loss: https://keras.io/losses/\n",
    "\n",
    "Documentation des metrics: https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 100)          140400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 6,145,756\n",
      "Trainable params: 6,145,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 774s 5ms/step - loss: 0.0566 - acc: 0.9804 - val_loss: 0.0466 - val_acc: 0.9827\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 755s 5ms/step - loss: 0.0404 - acc: 0.9846 - val_loss: 0.0451 - val_acc: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb501eb1cc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = pd.read_csv(config['FILES']['LABEL'])\n",
    "test_label_strip = test_label[test_label.toxic != -1]\n",
    "yt = test_label_strip[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63978/63978 [==============================] - 55s 867us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06546974438924606, 0.9729073932009209]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_te[test_label_strip.index], yt, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'accuracy calculée est la moyenne des accuracys de chaque problème binaire. L'accuracy de chaque problème binaire est le ratio entre le nombre de réponses correctes et le nombre de commentaires à classifier (// à la fonction accuracy_score de sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t = model.predict(X_te, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8853824752258589\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(yt, y_pred_t[test_label_strip.index].round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un problème multi-label, la fonction accuracy_score considère le groupe de label entier et pas des sous problèmes binaires. Par exemple, si on prédit [1,0,0,0,0,0] pour un commentaire alors qu'en réalité les labels sont [1,0,1,0,0,0], on considérera la réponse fausse (valeur 0) même si on avait réussi à prédire le premier label. On prédit plus rarement tout les labels correctements pour un même commentaire qu'on ne prédit indépendamment chaque label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Traitement du label toxic\n",
      "L'accuracy du jeu test est 0.9275844821657445\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[54294  3594]\n",
      " [ 1039  5051]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     57888\n",
      "           1       0.58      0.83      0.69      6090\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     63978\n",
      "   macro avg       0.78      0.88      0.82     63978\n",
      "weighted avg       0.94      0.93      0.93     63978\n",
      "\n",
      "... Traitement du label severe_toxic\n",
      "L'accuracy du jeu test est 0.9935915470943136\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[63504   107]\n",
      " [  303    64]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.37      0.17      0.24       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.68      0.59      0.62     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "... Traitement du label obscene\n",
      "L'accuracy du jeu test est 0.9631279502328925\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[58760  1527]\n",
      " [  832  2859]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     60287\n",
      "           1       0.65      0.77      0.71      3691\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     63978\n",
      "   macro avg       0.82      0.87      0.84     63978\n",
      "weighted avg       0.97      0.96      0.96     63978\n",
      "\n",
      "... Traitement du label threat\n",
      "L'accuracy du jeu test est 0.9967019913095126\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[63746    21]\n",
      " [  190    21]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.50      0.10      0.17       211\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     63978\n",
      "   macro avg       0.75      0.55      0.58     63978\n",
      "weighted avg       1.00      1.00      1.00     63978\n",
      "\n",
      "... Traitement du label insult\n",
      "L'accuracy du jeu test est 0.9650192253587171\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[59393  1158]\n",
      " [ 1080  2347]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     60551\n",
      "           1       0.67      0.68      0.68      3427\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     63978\n",
      "   macro avg       0.83      0.83      0.83     63978\n",
      "weighted avg       0.97      0.97      0.97     63978\n",
      "\n",
      "... Traitement du label identity_hate\n",
      "L'accuracy du jeu test est 0.9914189252555566\n",
      "Matrice de confusion sur le jeu test:\n",
      "[[63088   178]\n",
      " [  371   341]]\n",
      "Rapport : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63266\n",
      "           1       0.66      0.48      0.55       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.83      0.74      0.77     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "La Moyenne des accuracy est de 0.9729073535694562\n"
     ]
    }
   ],
   "source": [
    "# Classification pour chaque label de façon indépendante\n",
    "list_acc = [] \n",
    "for label in range(0,6):\n",
    "    print('... Traitement du label {}'.format(list_classes[label]))\n",
    "    # On calcule l'accuracy des prédictions\n",
    "    acc = accuracy_score(yt[:,label], y_pred_t[test_label_strip.index, label].round())\n",
    "    list_acc.append(acc)\n",
    "    print('L\\'accuracy du jeu test est {}'.format(acc))\n",
    "    print('Matrice de confusion sur le jeu test:')\n",
    "    print(confusion_matrix(yt[:,label], y_pred_t[test_label_strip.index, label].round()))\n",
    "    print('Rapport : ')\n",
    "    print(classification_report(yt[:,label], y_pred_t[test_label_strip.index, label].round()) )\n",
    "print('La Moyenne des accuracy est de {}'.format(np.mean(list_acc)))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on calcule l'accuracy pour chaque label de façon indépendante, les labels peu représentés (threat) sont en réalité mal prédits. On reconfirme le calcul effectué par Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tan = y\n",
    "y_tan = np.where(y_tan==0,-1,y_tan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remplace les 0 par des -1 en vue d'appliquer la fonction d'activation tanh et la loss hinge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"tanh\")(x)\n",
    "model2 = Model(inputs=inp, outputs=x)\n",
    "model2.compile(loss='hinge', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 768s 5ms/step - loss: 0.9635 - acc: 0.8329 - val_loss: 0.9627 - val_acc: 0.9620\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 869s 6ms/step - loss: 0.9634 - acc: 0.9427 - val_loss: 0.9627 - val_acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4fabca5c0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_t, y_tan, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_tan = yt\n",
    "yt_tan = np.where(yt_tan==0,-1,yt_tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384/63978 [======>.......................] - ETA: 45s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-46f661e42a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_label_strip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_tan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Fil_Rouge/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/Fil_Rouge/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Fil_Rouge/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Fil_Rouge/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Fil_Rouge/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.evaluate(X_te[test_label_strip.index], yt_tan, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t2 = model2.predict(X_te, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(yt_tan, y_pred_t2[test_label_strip.index].round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(0,6):\n",
    "    print('... Traitement du label {}'.format(list_classes[label]))\n",
    "    # On calcule l'accuracy des prédictions\n",
    "    acc = accuracy_score(yt_tan[:,label], y_pred_t2[test_label_strip.index, label].round())\n",
    "    print('L\\'accuracy du jeu test est {}'.format(acc))\n",
    "    print('Matrice de confusion sur le jeu test:')\n",
    "    print(confusion_matrix(yt_tan[:,label], y_pred_t2[test_label_strip.index, label].round()))\n",
    "    print('Rapport : ')\n",
    "    print(classification_report(yt_tan[:,label], y_pred_t2[test_label_strip.index, label].round()) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
