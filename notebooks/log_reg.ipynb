{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a constitué une première manipulation des données. Il est inspiré du notebook https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "import re\n",
    "# import and instantiate TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import and instantiate the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configparser permet d'utiliser un fichier de configuraiton (config.cfg) pour le projet. Cela évite de mettre en ligne sur le git des informations sensibles comme l'architecture des répertoires de la machine de travail.\n",
    "Un template config.dist est disponible sur le git pour définir les clés de configuration à utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension du jeu test\n",
      "(153164, 2)\n",
      "\n",
      "Echantillon des identifiants du jeu test\n",
      "0    00001cee341fdb12\n",
      "1    0000247867823ef7\n",
      "2    00013b17ad220c46\n",
      "3    00017563c3f7919a\n",
      "4    00017695ad8997eb\n",
      "Name: id, dtype: object\n",
      "\n",
      "Dimension du fichier label du jeu test\n",
      "(153164, 7)\n",
      "\n",
      "Echantillon des identifiants dont les labels sont disponibles dans le jeu test\n",
      "0    00001cee341fdb12\n",
      "1    0000247867823ef7\n",
      "2    00013b17ad220c46\n",
      "3    00017563c3f7919a\n",
      "4    00017695ad8997eb\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.cfg')\n",
    "# Chargement des données sous forme de dataframes pandas\n",
    "train_df = pd.read_csv(config['FILES']['TRAIN'])\n",
    "test_df = pd.read_csv(config['FILES']['TEST'])\n",
    "\n",
    "print('Dimension du jeu test')\n",
    "print(test_df.shape)\n",
    "\n",
    "print('\\nEchantillon des identifiants du jeu test')\n",
    "print(test_df['id'][0:5])\n",
    "\n",
    "# Chargement des labels du jeu test, donnés ultérieurement à la compétition \n",
    "test_label = pd.read_csv(config['FILES']['LABEL'])\n",
    "print('\\nDimension du fichier label du jeu test')\n",
    "print(test_label.shape)\n",
    "print('\\nEchantillon des identifiants dont les labels sont disponibles dans le jeu test')\n",
    "print(test_label['id'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des différents labels disponibles sous forme de liste\n",
    "cols_name = ['obscene', 'insult', 'toxic', 'severe_toxic', 'identity_hate', 'threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str)->list:\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage du texte. \n",
    "    1. Le texte est réduit à des minuscules.\n",
    "    2. Les contractions sont remplacées par le mot complet.\n",
    "    3. Le texte est découpé en liste en utlisant l'espace comme séparateur\n",
    "    \n",
    "    Args: \n",
    "        text, le texte à modifier\n",
    "    \n",
    "    Returns:\n",
    "        text, texte modifié\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    for change in [(r\"what's\", \"what is \"), (r\"\\'s\", \" \"), (r\"\\'ve\", \" have \"), (r\"can't\", \"cannot \"), \n",
    "                   (r\"n't\", \" not \"), (r\"i'm\", \"i am \"), (r\"\\'re\", \" are \"), (r\"\\'d\", \" would \"), (r\"\\'ll\", \" will \"), (r\"\\'scuse\", \" excuse \")]:\n",
    "        text = re.sub(change[0], change[1], text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction de nettoyage au jeu d'entrainement et test\n",
    "train_df['comment_text'] = train_df['comment_text'].map(lambda com: clean_text(com))\n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda com: clean_text(com))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation de TfidfVectorizer est disponible sur https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.comment_text\n",
    "x_test = test_df.comment_text\n",
    "\n",
    "# Conversion des données brutes en matrice TF-IDF\n",
    "# max_features: ne considére que les 5000 mots avec le TF-IDF le plus fort\n",
    "# stop_words: ne considère pas les mots implémentés dans l'option 'english' \n",
    "# (e.g petits mots très fréquents comme le, la, les)\n",
    "vect = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Apprentissage du vocabulaire présent dans le jeu d'entrainement, création d'une matrice document-terme\n",
    "# 1 ligne =  1 commentaire\n",
    "# 1 colonne = un des 5000 mots les plus fréquents dans le corpus\n",
    "x_train_tfid = vect.fit_transform(x_train)\n",
    "\n",
    "# Création d'une matrice document-terme à partir des commentaires du jeu test préalablement entrainé\n",
    "# les 5000 mots considérés sont ceux du jeu d'entrainement\n",
    "x_test_tfid = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de la matrice document-terme d'entrainement\n",
      "(159571, 5000)\n",
      "\n",
      "Dimension de la matrice document-terme test\n",
      "(153164, 5000)\n"
     ]
    }
   ],
   "source": [
    "print('Dimension de la matrice document-terme d\\'entrainement')\n",
    "print(x_train_tfid.shape)\n",
    "print('\\nDimension de la matrice document-terme test')\n",
    "print(x_test_tfid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on choisit de traiter chaque label de façon indépendante. On passe d'une classification multi-label à une classification multi-classe.\n",
    "Pour cela, on utilise la régression logistique (voir doc: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training accuracy is 0.9832300355327722\n",
      "Test accuracy is 0.9632998843352403\n",
      "... Processing insult\n",
      "Training accuracy is 0.9755469352200588\n",
      "Test accuracy is 0.9620338241270436\n",
      "... Processing toxic\n",
      "Training accuracy is 0.9639846839337975\n",
      "Test accuracy is 0.9243021038481978\n",
      "... Processing severe_toxic\n",
      "Training accuracy is 0.9920787611784097\n",
      "Test accuracy is 0.9924192691237613\n",
      "... Processing identity_hate\n",
      "Training accuracy is 0.9939713356436947\n",
      "Test accuracy is 0.9903716902685298\n",
      "... Processing threat\n",
      "Training accuracy is 0.9981199591404453\n",
      "Test accuracy is 0.9959204726624777\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=12.0)\n",
    "# C est l'inverse du facteur de régulation lambda. Ici, C est grand donc la régulation est faible. \n",
    "# Choix non justifié dans le notebook initial, nous n'avons pas fait varier ce paramètre\n",
    "\n",
    "# Tout les commentaires n'ont pas été utilisés lors de la validation de la compétition. \n",
    "# Certains commentaires tests ont le label -1, ils faut les enlever pour le calcul de performance\n",
    "test_label_strip = test_label[test_label.toxic != -1]\n",
    "\n",
    "# Classification pour chaque label de façon indépendante\n",
    "for label in cols_name:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]\n",
    "    yt = test_label_strip[label]\n",
    "    # on entraine le modele avec la matrice TF-IDF d'entrainement et ses labels\n",
    "    logreg.fit(x_train_tfid, y)\n",
    "    # on prédit ensuite les labels du jeu d'entrainement et du jeu test avec le modèle entrainé\n",
    "    y_pred_X = logreg.predict(x_train_tfid)\n",
    "    y_pred_t = logreg.predict(x_test_tfid)\n",
    "    # On calcule l'accuracy des prédictions\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(yt, y_pred_t[test_label_strip.index])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation de l'accuracy:  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "Elle renvoie la fraction de labels correctement classés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
