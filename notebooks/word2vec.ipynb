{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Embedding, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.cfg')\n",
    "train_df = csv.reader(open(config['FILES']['TRAIN'],'r'))\n",
    "test_df = csv.reader(open(config['FILES']['TEST'], 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(df):\n",
    "    data = []\n",
    "    for comment in df:\n",
    "        data.append(comment)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = save_csv(train_df)\n",
    "test_df = save_csv(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sentences(df):\n",
    "    sentences = dict()\n",
    "    for comment in df:\n",
    "        if comment[0]!= 'id':\n",
    "            sentences[comment[0]] = re.split('\\s|\\n',comment[1])\n",
    "    return sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000997932d777bf', \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\", '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_df[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted?', 'They', \"weren't\", 'vandalisms,', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC.', 'And', 'please', \"don't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"I'm\", 'retired', 'now.89.205.38.27']\n"
     ]
    }
   ],
   "source": [
    "sentences = my_sentences(train_df)\n",
    "print(sentences['0000997932d777bf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_tmpfile(\"vectors.kv\")\n",
    "word_vectors.save(fname)\n",
    "word_vectors = KeyedVectors.load(fname, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sentences=sentences, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2VecVocab at 0x7f161d56e2e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fuck' in word_vectors.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors['fuck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hell', 0.7634199857711792),\n",
       " ('suck', 0.7432746291160583),\n",
       " ('fucking', 0.6960117220878601),\n",
       " ('Fuck', 0.6941840052604675),\n",
       " ('ass', 0.6930743455886841),\n",
       " ('bitch', 0.6835107207298279),\n",
       " ('shit', 0.6786351203918457),\n",
       " ('dick', 0.6692777276039124),\n",
       " ('fagget.', 0.6593355536460876),\n",
       " ('kiss', 0.6322335004806519)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the to\n"
     ]
    }
   ],
   "source": [
    "# get the most common words\n",
    "print(word_vectors.index2word[0], word_vectors.index2word[1], word_vectors.index2word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M.; immunoreactivity Vellalars\n"
     ]
    }
   ],
   "source": [
    "# get the least common words\n",
    "vocab_size = len(model.wv.vocab)\n",
    "print(word_vectors.index2word[vocab_size - 1], word_vectors.index2word[vocab_size - 2], word_vectors.index2word[vocab_size - 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of \"of\" is: 3\n",
      "Index of \"to\" is: 2\n"
     ]
    }
   ],
   "source": [
    "# find the index of the 2nd most common word (\"of\")\n",
    "print('Index of \"of\" is: {}'.format(model.wv.vocab['of'].index))\n",
    "print('Index of \"to\" is: {}'.format(model.wv.vocab['to'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106027\n"
     ]
    }
   ],
   "source": [
    "# some similarity fun\n",
    "print(model.wv.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice\n"
     ]
    }
   ],
   "source": [
    "# what doesn't fit?\n",
    "print(model.wv.doesnt_match(['kiss', 'fuck', 'nice', 'suck']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
